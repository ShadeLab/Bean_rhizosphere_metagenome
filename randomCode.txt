
reformat.sh in=/mnt/home/stopnise/20191206_DNASeq_PE150/P5RW_S9_L006_R#_001.fastq.gz out=/mnt/research/ShadeLab/Guedes/P5RW.fq.gz
reformat.sh in=/mnt/home/stopnise/20191206_DNASeq_PE150/P6RW_S11_L006_R#_001.fastq.gz out=/mnt/research/ShadeLab/Guedes/P6RW.fq.gz

bbduk.sh in=/mnt/research/ShadeLab/Guedes/P5RW.fq.gz out=/mnt/research/ShadeLab/Guedes/P5RW_filtered.fq.gz ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/adapters.fa tpe tbo qtrim=rl trimq=10

bbduk.sh in=/mnt/research/ShadeLab/Guedes/P6RW.fq.gz out=/mnt/research/ShadeLab/Guedes/P6RW_filtered.fq.gz ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/adapters.fa tpe tbo qtrim=rl trimq=10

bbduk.sh in=P5RW_filtered.fq out=P5RW_QC_filtered.fq outm=P5RW.phiX.fq ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/phix174_ill.ref.fa.gz
bbduk.sh in=P6RW_filtered.fq out=P6RW_QC_filtered.fq outm=P6RW.phiX.fq ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/phix174_ill.ref.fa.gz


#!/bin/bash --login
########## Define Resources Needed with SBATCH Lines ##########
 
#SBATCH --time=12:00:00               # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --ntasks=16                   # number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --nodes=1-4
#SBATCH --cpus-per-task=4             # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem=400G                    # memory required per node - amount of memory (in bytes)
#SBATCH --job-name megahit_run       # you can give your job a name for easier identification (same as -J)
#SBATCH --mail-user=stopnise@msu.edu
#SBATCH --mail-type=BEGIN,END 
#SBATCH -A shadeash-colej
 
########## Command Lines to Run ##########
cd /mnt/research/ShadeLab/Guedes/

for sample in P5RW_filtered.fq P6RW_filtered.fq 
do
megahit --12 $file -o ${sample%_filtered.fq}_megahit_assembly --k-min 27 --k-max 127 --k-step 10 -t 24
done



/opt/bifxapps/idba-1.1.3/bin/idba_ud -r reads.fa -o idba_ud_out_test


mkdir annotation
dir= annotation
for sample in $(<sampleID.txt)
do
prokka anvio_work/${sample}_contigs.fa --proteins ${sample}.gbk --outdir ${dir} --prefix ${sample} --cpus 24 --norrna --notrna --metagenome
done

prokka anvio_work/combined_contigs.fa --proteins combined.gbk --outdir combined --prefix combined --cpus 20 --norrna --notrna --metagenome


cat MRF_pod_combined.fastq_QC_filtered.fq | paste - - - - | awk 'BEGIN{FS="\t"}{print ">"substr($1,2)"\n"$2}' > MRF_pod_filt.fa


#!/bin/bash --login
########## Define Resources Needed with SBATCH Lines ##########
 
#SBATCH --time=15:00:00               # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --ntasks=2                   # number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --cpus-per-task=10             # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem-per-cpu=100G                    # memory required per node - amount of memory (in bytes)
#SBATCH --job-name QC_samples       # you can give your job a name for easier identification (same as -J)
#SBATCH --mail-user=stopnise@msu.edu
#SBATCH --mail-type=BEGIN,END 
#SBATCH -A shadeash-colej
 
########## Command Lines to Run ##########
cd /mnt/research/ShadeLab/Stopnisek/bean_metaG/

mkdir all_samples

for file in $(<all_samples_short.txt)
do

reformat.sh in=${file}_R#_001.fastq.gz out=all_samples/${file}.fq.gz

bbduk.sh in=all_samples/${file}.fq.gz out=all_samples/${file}.filtered.fq.gz ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/adapters.fa tpe tbo qtrim=rl trimq=10

bbduk.sh in=all_samples/${file}.filtered.fq.gz out=all_samples/${file}.filtered.QC.fq.gz outm=all_samples/${file}.phiX.fq ref=/mnt/home/stopnise/anaconda/opt/bbmap-38.73-0/resources/phix174_ill.ref.fa.gz

done



#3/13/2020
# bowtie2 finished now need to convert sam to bam

cd anvio_work/mapping/

for sample in *.bowtie2.sam
do
samtools view -bS ${sample} > $PWD/${sample%.sam}.bam
done


#using anvio to sort and index bam files
#for sample in `cat SAMPLE_IDs`; do anvi-init-bam $sample-RAW.bam -o $sample.bam; done

cd anvio_work/mapping/

#for sample in *.bowtie2.bam
#do
#anvi-init-bam $sample -o $PWD/${sample%.bam}.anvio.bam
#done

#anvi-display-contigs-stats combined_contigs.db --report-as-text $PWD/anvi.db.stat




cd /mnt/research/ShadeLab/Stopnisek/bean_metaG

cat all_samples/*R1.fq.gz > /mnt/scratch/stopnise/Maxbin2/bean.R1.fq.gz
cat all_samples/*R2.fq.gz > /mnt/scratch/stopnise/Maxbin2/bean.R2.fq.gz

run_MaxBin.pl -contig anvio_work/combined_contigs.fa -reads /mnt/scratch/stopnise/Maxbin2/bean.R1.fq.gz -reads2 /mnt/scratch/stopnise/Maxbin2/bean.R2.fq.gz -out /mnt/scratch/stopnise/MaxBin2/ -thread 36




for sample in *pod*bowtie2.anvio.bam
do
anvi-profile -i $sample -c ../combined_contigs_new.db -T 36 --skip-SNV-profiling
done

for file in *; do ../usearch64 -otutab_stats $file -output ../table_stats/${file%_OTU_table.txt}_stats_table.txt; done

usearch -fastx_get_sample_names reads.fa -output samples.txt





for file in *.fastq; do mv -v $file ${file/_/_R}; done

for sample in $(<$PRJNA437232_v2.txt)
do
repair.sh in1=PRJNA437232/${sample}_R1.fastq in2=PRJNA437232/${sample}_R2.fastq out1=PRJNA437232_fixed/${sample}_R1.fastq out2=PRJNA437232_fixed/${sample}_R2.fastq outs=PRJNA437232_fixed/singletons.fq
done
